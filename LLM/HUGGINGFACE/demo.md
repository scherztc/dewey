## AI Hub Features

### Model Hub
- **PreTrained Models**
- **Inference API (Remotely)**

### Open Source Libraries
- **Transformers**
- **Pipeline**
- **Supports PyTorch and Tensorflow

### Datasets
- **Training**
- **Evaluation**
- **Tuning**

### Spaces
- **Playground**

## Alternatives to Using Huggingface Locally with REST API

- **Ollama**
- **LM Studio**
- **LLama.cpp**
- **VRM**

## Tools for Running Models Locally (If Hardware Supports AI)

- **Image Classifier**: `python3 image_classification_using_ai.py`
- **Sentiment Classifier**: `python3 sentiment_classifier.py`
- **Task Supported List**: `python3 task_list_pipeline.py`
- **Named Entity Recognition**: `python3 ner_using_pipeline.py`
- **Text Translator**: `python3 translate_text.py`
- **RAG**: `python3 LLM_RAG_Full.py`
- **Dataset Analyzer without Sharing your Data**: `python3 dataset_analyzer.py`

## Downloading and Running Pre-trained Models Using the Transformers Library
- **Autotrain

### Using The Transformers Library
- `load using_the_transforms_library.py`
- `load preparing_the_images.py`
- `load detecting_objects.py`
- `load draw_image.py`

## Simplifying LLM Tasks Using the Pipeline Object
- **Keras ->TensorFlow
- **Seaborn -> MatLab
- **Image Classifier with Pipeline**: `image_classification_using_pipeline.py`

## Deploying LLM Applications Using Gradio and Pipelines
- ** Libraries Needed : ChainLit and StreamLit

- `load objection_detection.py`
- `load image_segmentation.py`

### Using Gradio

## Using LLM to Query Your Private Data Using RAG Data Stores
- ** Libraries Needed : llama_index

- `load LLM_RAG_Full.py`
- `load rag_pipeline.py`
- `load perform_word_vector.py`
- `load indexing_rag.py`
- `load loading_rag.py`
- `load using_an_llm_for_querying.py`
- `load asking_questions.py`


## Using LLM for dataset analysis
- ** Prompt Engineering

128 K TOKEN Context (Ask / Response)
Prompt with I have a dataset with this schema stored in the following format,
Answer the following questions ……
Note that 0 mean dead(false) and 1 means alive (true).
Return answer in python only
I have already loaded the CSV into datastreams called df.





